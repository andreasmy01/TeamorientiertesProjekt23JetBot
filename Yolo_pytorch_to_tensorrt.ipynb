{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organic-battery",
   "metadata": {},
   "source": [
    "# Yolo model PyTorch to TensorRT conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-thirty",
   "metadata": {},
   "source": [
    "> **ATTENTION** it is really important to have torch2trt with version **greater than v0.4.0** installed for the conversion to work!!!\n",
    "\n",
    "> (At the time of writing, we used the torch2trt master branch which was slightly ahead of v0.4.0)\n",
    "\n",
    ">After the model was sucessfully converted, the torch2trt version needs to be **v0.2.0 or v0.3.0** otherwise the inference will lead to errors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-policy",
   "metadata": {},
   "source": [
    "## Torch2TRT installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-portland",
   "metadata": {},
   "source": [
    "Clone torch2trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA-AI-IOT/torch2trt.git\n",
    "%cd torch2trt\n",
    "!git fetch --all --tags\n",
    "!git checkout master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-tribune",
   "metadata": {},
   "source": [
    "Install the python library and plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 setup.py install\n",
    "!cmake -B build . && cmake --build build --target install && ldconfig\n",
    "!python3 setup.py install --plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-copyright",
   "metadata": {},
   "source": [
    "## Model Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-tracker",
   "metadata": {},
   "source": [
    "1. Add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch2trt import torch2trt, TRTModule\n",
    "from libjetbot.handles.ObjectDetectionHandle import ObjectDetectionHandle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-insured",
   "metadata": {},
   "source": [
    "2. Load the pytorch yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "odh = ObjectDetectionHandle(\"JetbotYolo/weights/obj_det_model_yolov5n.pt\")\n",
    "model = odh.yolo.Object_detector.yolo_model\n",
    "\n",
    "# defines input shape. Inference with tensorRT will only work with the dimensions specified here\n",
    "x = torch.ones((1, 3, 224, 224)).cuda() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-smoke",
   "metadata": {},
   "source": [
    "3. Convert yolo pytorch model to tensorRT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trt = torch2trt(model, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-evening",
   "metadata": {},
   "source": [
    "4. Save the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_trt.state_dict(), 'object_detection_model_trt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-vulnerability",
   "metadata": {},
   "source": [
    "## Optional: Setup torch2trt version v0.3.0 for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd torch2trt\n",
    "!git checkout tags/v0.3.0\n",
    "!python3 setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-chicago",
   "metadata": {},
   "source": [
    "Now you should be able to use inference with the new YOLO tensorRT model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
